{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Naive Bayes is family of classification algorithms based on Bayes' theorem. It is a popular choice for various classification tasks due to its simplicity, efficiency, and interpretability.\n",
    "\n",
    "### Core principle\n",
    "Naive Bayes classifiers work under the assumption fo conditional independence between features (predictors) given the class label (target variable). In simpler terms, it assumes that knowing the value of one feature does not influence the probability of another feature's value, as long as the class label is already known. While this assumption is not always hold true in reality, it often works well in practive for many classification problems.\n",
    "\n",
    "### Classification process\n",
    "- Training: The model learns from the labeled dataset where each data point has features and a corresponding class label.\n",
    "- Prediction: For a new unseen data point, the model calculates the probability of it belonging to each class. It achieves this by,\n",
    "    1. Using Bayes' theorem to compute the posterior probability (probability of a class given the features).\n",
    "    2. Assuming conditional independence between features, which simplifies the calculations.\n",
    "    3. Multiplying the probabilities of each feature value given the class and multiplying by the prior probability of the class itself (learned from the training data).\n",
    "- Assigning class label: The class with the highest posterior probability is assigned as the predicted class for the new data point.\n",
    "\n",
    "### Example\n",
    "Imagine emails are being classified as spam or not spam based on features like наличиe слова \"деньги\" (presence of the word \"money\") and наличие восклицательных знаков (presence of exclamation marks). Naive Bayes would assume that the presence of \"money\" doesn't influence the presence of exclamation marks (and vice versa) given the email class (spam or not spam).\n",
    "\n",
    "### Advantages of Naive Bayes\n",
    "- Simplicity and efficiency: Naive Bayes is easy to understand and implement, making it a good choice for beginners. It's also computationally efficient for training and prediction.\n",
    "- Interpretability: The model allows to understand how each feature contributes to the classification by examining the feature probabilities for each class.\n",
    "- Performance: Naive Bayes can perform well for various classification tasks, especially when dealing with high-dimensional data (many features).\n",
    "\n",
    "### Disadvantage of Naive Bayes\n",
    "- Conditional independence assumption: The assumption of conditional independence between features might not always be valid, which can lead to suboptimal performance in some cases.\n",
    "- Sensitivity to features: Naive Bayes can be sensitive to irrelevant features or features with many unique values. Feature selection or preprocessing techniques might be necessary for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes algorithm\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
