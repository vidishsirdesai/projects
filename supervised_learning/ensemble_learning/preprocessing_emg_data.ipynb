{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_theme(style = \"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following commands in the Terminal\n",
    "# cd emg_data\n",
    "# extract files, unrar x \"./emg.rar\" \"./\"\n",
    "# install tree sudo apt install tree\n",
    "# tree \"./EMG Physical Action Data Set/sub1\"\n",
    "# ls -lrt ./EMG\\ Physical\\ Action\\ Data\\ Set/sub1/Aggressive/txt/\n",
    "# cat ./EMG\\ Physical\\ Action\\ Data\\ Set/sub1/Aggressive/txt/Slapping.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the following commands in the command line (MacOS)\n",
    "# cd emg_data\n",
    "# extract files, tar -xf emg.rar\n",
    "# install brew, brew install tree\n",
    "# view the tree disgram of the file system in the EMG dataset directory, tree \"./EMG Physical Action Data Set/sub1\"\n",
    "# view the files in one of the node directories, ls -lrt ./EMG\\ Physical\\ Action\\ Data\\ Set/sub1/Aggressive/txt/\n",
    "# view the data in slappint.txt, cat ./EMG\\ Physical\\ Action\\ Data\\ Set/sub1/Aggressive/txt/Slapping.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Chunking\n",
    "Data chunking is a technique used to divide a large dataset into smaller, more manageable chunks. In the context of Electromyography (EMG) signals, chunking is employed to address the issue of data redundancy, where consequtive samples exhibit high similarity.\n",
    "\n",
    "### Why chunk EMG data?\n",
    "1. Redundancy reduction: By identifying and removing redundant data, chunking can significantly reduce the dataset's size.\n",
    "2. Improved training efficiency: Smaller datasets require less computational resourves and time for training Machine Learning models.\n",
    "3. Enhanced model performance: By focusing on unique information, models can learn more effectively and achieve better performance.\n",
    "\n",
    "### Chunking process\n",
    "1. Interval selection: The optimal chunk size depends on the specific dataset and application. In the given scenario, an interval size of 10 is chosen.\n",
    "2. Data segmentation: The dataset is divided into consecutive intervals of length 10.\n",
    "3. Feature extraction: For each interval, a representative feature is extracted, such as mean, median, or maximum value.\n",
    "\n",
    "### Note on data loss\n",
    "While chunking inevitably leads to some loss of information, the benefits often outweigh the drawbacks, especially when dealing with redundant data. The key is to choose an appropriate chunk size that balances data reduction with information preservation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xl/sjrt7p6548j9h6x1rz_px87w0000gn/T/ipykernel_96135/3433702783.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# chunking using max of every 10 sequential values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtemp_chunked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mtemp_chunked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_chunked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove the last 4 characters = \".txt\" from the filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "actions = {}\n",
    "data_dirs = [\n",
    "    \"./emg_data/EMG Physical Action Data Set/sub1/Aggressive/txt\",\n",
    "    \"./emg_data/EMG Physical Action Data Set/sub1/Normal/txt\"\n",
    "]\n",
    "ind = 0\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for dirs in data_dirs:\n",
    "    for files in os.listdir(dirs):\n",
    "        with open(os.path.join(dirs, files), \"r\") as file:\n",
    "            temp = pd.read_csv(\n",
    "                file.name,\n",
    "                sep = \"\\t\",\n",
    "                header = None,\n",
    "                names = [\"ch\" + str(i) for i in range(1, 9)]\n",
    "            )\n",
    "\n",
    "            # chunking using max of every 10 sequential values\n",
    "            temp_chunked = pd.DataFrame()\n",
    "\n",
    "            for i in range(0, len(temp), 10):\n",
    "                temp_chunked = temp_chunked.append(temp.iloc[i: i+10].max(), ignore_index = True)\n",
    "\n",
    "            labels = [files[: -4] for i in range(len(temp_chunked))] # remove the last 4 characters = \".txt\" from the filename\n",
    "            actions[files[: -4]] = ind\n",
    "\n",
    "            temp_chunked[\"Action\"] = labels\n",
    "\n",
    "            df = pd.concat([df, temp_chunked], ignore_index = True)\n",
    "\n",
    "            ind += 1\n",
    "\n",
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
