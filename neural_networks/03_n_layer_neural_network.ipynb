{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron (MLP)\n",
    "So far, the models built had only 3 neurons. But, what if more neurons were added to the network in the model to make it more complex in order to get the model to learn more complex patterns.\n",
    "\n",
    "<img src = \"../artifacts/neural_networks_23.png\" alt = \"drawing\" width = \"500\">\n",
    "\n",
    "There are 2 features which are passed as inputs and 3 classes which are obtained as output.\n",
    "\n",
    "In the above figure, superscript notation is used to represent the layer. Therefore, representing with $f_1$, $f_1^1$ is used (i.e., neuron 1 of layer 1).\n",
    "\n",
    "The inputs (layer 0 or input layer) is connected with 4 neurons of layer 1. These 4 neurons are connected with 3 neurons of the output layers (layer 2).\n",
    "\n",
    "This intermediate layer in between the input and output is called hidden layer.\n",
    "\n",
    "### Why is it called hidden layer?\n",
    "Both input and output are hidden from this layer and this layer is not directly dealt with. Hence, it is called a hidden layer.\n",
    "\n",
    "The network can be made complex by increasing the number of neurons in the hidden layer or by increasing the number of hidden layers.\n",
    "\n",
    "<img src = \"../artifacts/neural_networks_24.png\" alt = \"drawing\" width = \"500\">\n",
    "\n",
    "### What will the activation function of the output layer be?\n",
    "Since this is a multi-class classification problem, the activation function will be softmax.\n",
    "\n",
    "### What will the activation function of the hidden layer be?\n",
    "Since the model needs to learn a non-linear decision boundary, the activation functions will also have to be non-linear.\n",
    "\n",
    "### What happens if each activation function in MLP is linear?\n",
    "Consider the following example to understand,\n",
    "\n",
    "Given, $f(x) = 2x + 1$, $g(x) = 3x + 2$, will $f(g(x))$ be linear or non-linear?\n",
    "\n",
    "<img src = \"../artifacts/neural_networks_25.png\" alt = \"drawing\" width = \"500\">\n",
    "\n",
    "Composition of 2 linear function is linear. If the activation function used is linear, then the model will also be linear. But in this case, a non-linear model is required.\n",
    "\n",
    "### How can a non-linear activation function help?\n",
    "Consider, $f(x) = x^2 + 1$, $g(x) = 2x + 1$, will $g(f(x))$ be linear or non-linear?\n",
    "\n",
    "<img src = \"../artifacts/neural_networks_26.png\" alt = \"drawing\" width = \"500\">\n",
    "\n",
    "### What if another non-linear function stacked?\n",
    "Consider, $h(x) = x^2 + 1$, $f(x) = 2x^2 + 1$, and $g(x) = x + 1$,\n",
    "\n",
    "<img src = \"../artifacts/neural_networks_27.png\" alt = \"drawing\" width = \"500\">\n",
    "\n",
    "Therefore, stacking a non-linear function over a linear function and repeating the process may create complex features.\n",
    "\n",
    "Suppose there are 2 inputs $x_1$ and $x_2$, the computation graph will look as follows,\n",
    "\n",
    "<img src = \"../artifacts/neural_networks_28.png\" alt = \"drawing\" width = \"500\">\n",
    "\n",
    "Explanation,\n",
    "- $z$ is the weighted sum, hence it will be linear, $z = 3x_1 + 4x_2$.\n",
    "- $a_1$ will be non-linear and complex, $a_1 = 9x_1^2 + 16x_2^2 + 24x_1x_2$.\n",
    "- $a_2$ will be non-linear and much more complex than $a_1$, $a_2 = (9x_1^2 + 16x_2^2 + 24x_1x_2 +1)^2 = (9x_1^2 + 16x_2^2)^2 + 2(9x_1^2 + 16x_2^2)(24x_1x_2 +1) + (24x_1x_2 +1)^2$\n",
    "\n",
    "### What non-linear function should be used as the activation function?\n",
    "Recall that, sigmoid is one of the non-linear activation function.\n",
    "\n",
    "### Should different activation functions be used in different layers?\n",
    "Theoritically, it is very much possible to use different activation functions in different layers. But, studies have shown that doing so does not add much value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
